{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TP1 - 22.45 Redes Neuronales - Regresión Logística y Lineal"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Regresión Logística"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import required libraries and dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxCoqneHzZWv"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import datetime\n",
        "from os.path import exists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers.experimental import preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Download and load Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pV2lRjoRzhMp",
        "outputId": "09ef645e-5429-48bc-f417-675b9dc915cf"
      },
      "outputs": [],
      "source": [
        "(train_X, train_y), (test_X, test_y) = fashion_mnist.load_data()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Normalize the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_max = np.max(train_X)\n",
        "train_X = train_X.astype('float32') / data_max\n",
        "test_X = test_X.astype('float32') / data_max\n",
        "np.max(train_X)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exploratory Data Analysis"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Example: Show the first object of the train dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "h8Nl-PvPzjJT",
        "outputId": "38bf581a-4815-42df-9fe8-e791aca9f279"
      },
      "outputs": [],
      "source": [
        "plt.imshow(train_X[0,...], cmap=\"gray\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Show a few instances of each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(40, 40))  # width, height in inches\n",
        "\n",
        "# idx works on np.array and not lists.\n",
        "idx = np.argsort(train_y)\n",
        "\n",
        "train_X_sorted = np.array(train_X)[idx]\n",
        "train_y_sorted = np.array(train_y)[idx]\n",
        "\n",
        "count = 0\n",
        "\n",
        "for i in range(100):\n",
        "    count = int(np.floor(i / 10))\n",
        "    sub = fig.add_subplot(10, 10, i + 1, xticks=[], yticks=[])\n",
        "    sub.imshow(train_X_sorted[i + count * 6000,:,:], interpolation='nearest', cmap='gray')\n",
        "    sub.set_title('Category: ' + str(train_y_sorted[i + count * 6000]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Look at the data distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "unique, counts = np.unique(train_y, return_counts=True)\n",
        "print(dict(zip(unique, counts)))\n",
        "\n",
        "counts = np.bincount(train_y)\n",
        "print(counts)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "ax.bar(range(10), counts, width=0.8, align='center')\n",
        "ax.set(xticks=range(10), xlim=[-1, 10], title='Training data distribution')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "unique, counts = np.unique(test_y, return_counts=True)\n",
        "print(dict(zip(unique, counts)))\n",
        "\n",
        "counts = np.bincount(test_y)\n",
        "print(counts)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "ax.bar(range(10), counts, width=0.8, align='center')\n",
        "ax.set(xticks=range(10), xlim=[-1, 10], title='Testing data distribution')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convert the dataset from a vector form to a categorical distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_classes = np.max(train_y) + 1\n",
        "train_y_cat = utils.to_categorical(train_y, num_classes)\n",
        "test_y_cat = utils.to_categorical(test_y, num_classes)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Softmax"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Config the model to be trained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#train_X = train_X.reshape(train_X.shape[0], 28, 28, 1).astype('float32')\n",
        "#test_X = test_X.reshape(test_X.shape[0], 28, 28, 1).astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vc7g_gev2apS"
      },
      "outputs": [],
      "source": [
        "softmax_model =  Sequential()\n",
        "#model.add(preprocessing.RandomFlip(\"horizontal\", input_shape=(28,28,1)))\n",
        "# model.add(layers.Dropout(0.1, input_shape=(28,28)))\n",
        "softmax_model.add(layers.Flatten(input_shape=(28,28)))\n",
        "softmax_model.add(layers.Dense(128, activation=\"relu\"))\n",
        "softmax_model.add(layers.Dense(num_classes, activation=\"softmax\"))\n",
        "softmax_model.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fu4LHsfg2fx0"
      },
      "outputs": [],
      "source": [
        "softmax_model.compile(loss = 'categorical_crossentropy', optimizer=SGD(learning_rate=0.0002, momentum=0.95),metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Callback to stop training if, after 2 epochs, the accuracy is not improving\n",
        "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Callback to save the weights of the best model\n",
        "checkpoint_filepath = '/tmp/checkpoint/softmax'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Logs and metrics from TensorBoard\n",
        "log_dir = \"logs/fit/softmax/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Fit the model to the train data and validate it with the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We load the previously best weights to save time on training\n",
        "# if (exists(checkpoint_filepath)):\n",
        "    # softmax_model.load_weights(checkpoint_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvNQ1f9C3Ory",
        "outputId": "1b5f8cfa-4f8d-4532-c436-497bd26313d6"
      },
      "outputs": [],
      "source": [
        "softmax_history = softmax_model.fit(train_X, train_y_cat, validation_data=(test_X, test_y_cat), batch_size = 64, epochs=10, callbacks=[tensorboard_callback, early_stop_callback])\n",
        "# softmax_history = softmax_model.fit(train_X, train_y_cat, validation_data=(test_X, test_y_cat), batch_size = 64, epochs=10, callbacks=[model_checkpoint_callback, tensorboard_callback, early_stop_callback])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Plot important metrics"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### TensorBoard session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs/fit"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "3-YPKw9V3pfW",
        "outputId": "a509a96e-d168-4c1d-ccb9-185ddda13bf4"
      },
      "outputs": [],
      "source": [
        "plt.plot(softmax_history.history[\"loss\"], label=\"train\")\n",
        "plt.plot(softmax_history.history[\"val_loss\"], label=\"val\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "vYsmvi626L2g",
        "outputId": "227c99c2-6808-47e3-ad82-be7470ced0a1"
      },
      "outputs": [],
      "source": [
        "plt.plot(softmax_history.history[\"accuracy\"], label=\"train\")\n",
        "plt.plot(softmax_history.history[\"val_accuracy\"], label=\"val\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlp_model = Sequential()\n",
        "mlp_model.add(layers.Flatten(input_shape=(28,28)))\n",
        "mlp_model.add(layers.Dense(256, activation='relu'))\n",
        "mlp_model.add(layers.Dense(64, activation='relu'))\n",
        "mlp_model.add(layers.Dense(num_classes, activation=\"softmax\"))\n",
        "mlp_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlp_model.compile(loss = 'categorical_crossentropy', optimizer=SGD(learning_rate=0.0002, momentum=0.95),metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Callback to stop training if, after 2 epochs, the accuracy is not improving\n",
        "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Callback to save the weights of the best model\n",
        "checkpoint_filepath = '/tmp/checkpoint/mlp'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Logs and metrics from TensorBoard\n",
        "log_dir = \"logs/fit/mlp/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Fit the model to the train data and validate it with the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We load the previously best weights to save time on training\n",
        "# if (exists(checkpoint_filepath)):\n",
        "    # mlp_model.load_weights(checkpoint_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlp_history = mlp_model.fit(train_X, train_y_cat, validation_data=(test_X, test_y_cat), batch_size = 64, epochs=10, callbacks=[tensorboard_callback, early_stop_callback])\n",
        "# softmax_history = softmax_model.fit(train_X, train_y_cat, validation_data=(test_X, test_y_cat), batch_size = 64, epochs=10, callbacks=[model_checkpoint_callback, tensorboard_callback, early_stop_callback])\n",
        "# mlp_history = mlp_model.fit(train_X, train_y_cat, validation_data=(test_X, test_y_cat), batch_size = 64, epochs=10, callbacks=[model_checkpoint_callback, tensorboard_callback, early_stop_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Plot important metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### TensorBoard session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs/fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(mlp_history.history[\"loss\"], label=\"train\")\n",
        "plt.plot(mlp_history.history[\"val_loss\"], label=\"val\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(mlp_history.history[\"accuracy\"], label=\"train\")\n",
        "plt.plot(mlp_history.history[\"val_accuracy\"], label=\"val\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
