{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TP1 - 22.45 Redes Neuronales - Regresión Logística y Lineal"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Regresión Logística"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import required libraries and dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxCoqneHzZWv"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import datetime\n",
        "from os.path import exists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers.experimental import preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from numpy import interp\n",
        "from itertools import cycle\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import tensorflow_addons as tfa\n",
        "from tensorboard.plugins.hparams import api as hp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Download and load Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pV2lRjoRzhMp",
        "outputId": "09ef645e-5429-48bc-f417-675b9dc915cf"
      },
      "outputs": [],
      "source": [
        "(train_X, train_y), (test_X, test_y) = fashion_mnist.load_data()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Normalize the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_max = np.max(train_X)\n",
        "train_X = train_X.astype('float32') / data_max\n",
        "test_X = test_X.astype('float32') / data_max\n",
        "np.max(train_X)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exploratory Data Analysis"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Example: Show the first object of the train dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "h8Nl-PvPzjJT",
        "outputId": "38bf581a-4815-42df-9fe8-e791aca9f279"
      },
      "outputs": [],
      "source": [
        "plt.imshow(train_X[0,...], cmap=\"gray\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Show a few instances of each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(40, 40))  # width, height in inches\n",
        "\n",
        "# idx works on np.array and not lists.\n",
        "idx = np.argsort(train_y)\n",
        "\n",
        "train_X_sorted = np.array(train_X)[idx]\n",
        "train_y_sorted = np.array(train_y)[idx]\n",
        "\n",
        "count = 0\n",
        "\n",
        "for i in range(100):\n",
        "    count = int(np.floor(i / 10))\n",
        "    sub = fig.add_subplot(10, 10, i + 1, xticks=[], yticks=[])\n",
        "    sub.imshow(train_X_sorted[i + count * 6000,:,:], interpolation='nearest', cmap='gray')\n",
        "    sub.set_title('Category: ' + str(train_y_sorted[i + count * 6000]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Look at the data distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "unique, counts = np.unique(train_y, return_counts=True)\n",
        "print(dict(zip(unique, counts)))\n",
        "\n",
        "counts = np.bincount(train_y)\n",
        "print(counts)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "ax.bar(range(10), counts, width=0.8, align='center')\n",
        "ax.set(xticks=range(10), xlim=[-1, 10], title='Training data distribution')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "unique, counts = np.unique(test_y, return_counts=True)\n",
        "print(dict(zip(unique, counts)))\n",
        "\n",
        "counts = np.bincount(test_y)\n",
        "print(counts)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "ax.bar(range(10), counts, width=0.8, align='center')\n",
        "ax.set(xticks=range(10), xlim=[-1, 10], title='Testing data distribution')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convert the dataset from a vector form to a categorical distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_classes = np.max(train_y) + 1\n",
        "train_y_cat = utils.to_categorical(train_y, num_classes)\n",
        "test_y_cat = utils.to_categorical(test_y, num_classes)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Softmax"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Config the model to be trained"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "METRICS = [\n",
        "    hp.Metric(\n",
        "        \"epoch_accuracy\",\n",
        "        group=\"validation\",\n",
        "        display_name=\"accuracy (val.)\",\n",
        "    ),\n",
        "    hp.Metric(\n",
        "        \"epoch_loss\",\n",
        "        group=\"validation\",\n",
        "        display_name=\"loss (val.)\",\n",
        "    ),\n",
        "]\n",
        "\n",
        "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
        "HP_LEARN_RATE = hp.HParam('learning_rate', hp.Discrete([0.0001, 0.001, 0.01]))\n",
        "HP_MOMENTUM = hp.HParam('momentum', hp.Discrete([0.9, 0.95, 0.99]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Callback to stop training if, after 2 epochs, the accuracy is not improving\n",
        "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Callback to save the weights of the best model\n",
        "checkpoint_filepath = '/tmp/checkpoint/softmax'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Logs and metrics from TensorBoard\n",
        "log_dir = \"logs/softmax/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with tf.summary.create_file_writer(log_dir).as_default():\n",
        "  hp.hparams_config(\n",
        "    hparams=[HP_OPTIMIZER, HP_LEARN_RATE, HP_MOMENTUM],\n",
        "    metrics=METRICS,\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_test_model(hparams, run_dir):\n",
        "  softmax_model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax),\n",
        "  ])\n",
        "\n",
        "  if(hparams[HP_OPTIMIZER] == 'sgd'):\n",
        "    optimizer = SGD(learning_rate=hparams[HP_LEARN_RATE], momentum=hparams[HP_MOMENTUM])\n",
        "  elif(hparams[HP_OPTIMIZER] == 'adam'):\n",
        "    optimizer = Adam(learning_rate=hparams[HP_LEARN_RATE])\n",
        "\n",
        "  softmax_model.compile(\n",
        "      optimizer=optimizer,\n",
        "      loss='categorical_crossentropy',\n",
        "      metrics=[\"accuracy\"]\n",
        "  )\n",
        "\n",
        "  callbacks = [\n",
        "      early_stop_callback,\n",
        "      tf.keras.callbacks.TensorBoard(run_dir),# log metrics\n",
        "      hp.KerasCallback(run_dir, hparams),  # log hparams\n",
        "    ]\n",
        "\n",
        "  softmax_model.fit(train_X, train_y_cat, validation_data=(test_X, test_y_cat), batch_size = 128, epochs=1, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "session_num = 0\n",
        "\n",
        "for optimizer in HP_OPTIMIZER.domain.values:\n",
        "  for learning_rate in HP_LEARN_RATE.domain.values:\n",
        "    if(optimizer == 'sgd'):\n",
        "      for momentum in HP_MOMENTUM.domain.values:\n",
        "        hparams = {\n",
        "          HP_OPTIMIZER: optimizer,\n",
        "          HP_LEARN_RATE: learning_rate,\n",
        "          HP_MOMENTUM: momentum,\n",
        "        }\n",
        "        run_name = \"run-%d\" % session_num\n",
        "        print('--- Starting trial: %s' % run_name)\n",
        "        print({h.name: hparams[h] for h in hparams})\n",
        "        train_test_model(hparams, log_dir + run_name)\n",
        "        session_num += 1\n",
        "    else:\n",
        "      hparams = {\n",
        "          HP_OPTIMIZER: optimizer,\n",
        "          HP_LEARN_RATE: learning_rate,\n",
        "      }\n",
        "      run_name = \"run-%d\" % session_num\n",
        "      print('--- Starting trial: %s' % run_name)\n",
        "      print({h.name: hparams[h] for h in hparams})\n",
        "      train_test_model(hparams, log_dir + run_name)\n",
        "      session_num += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs/softmax/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#train_X = train_X.reshape(train_X.shape[0], 28, 28, 1).astype('float32')\n",
        "#test_X = test_X.reshape(test_X.shape[0], 28, 28, 1).astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vc7g_gev2apS"
      },
      "outputs": [],
      "source": [
        "softmax_model =  Sequential()\n",
        "#model.add(preprocessing.RandomFlip(\"horizontal\", input_shape=(28,28,1)))\n",
        "# model.add(layers.Dropout(0.1, input_shape=(28,28)))\n",
        "softmax_model.add(layers.Flatten(input_shape=(28,28)))\n",
        "softmax_model.add(layers.Dense(num_classes, activation=\"softmax\"))\n",
        "softmax_model.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Callback to stop training if, after 2 epochs, the accuracy is not improving\n",
        "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Callback to save the weights of the best model\n",
        "checkpoint_filepath = '/tmp/checkpoint/softmax'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Logs and metrics from TensorBoard\n",
        "log_dir_fit = \"logs/fit/softmax/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir_fit, histogram_freq=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fu4LHsfg2fx0"
      },
      "outputs": [],
      "source": [
        "optimizer = SGD(learning_rate=0.0002, momentum=0.95)\n",
        "softmax_model.compile(loss = 'categorical_crossentropy', optimizer=optimizer,metrics=[\"accuracy\", tfa.metrics.F1Score(average='macro',num_classes=num_classes),tfa.metrics.F1Score(average='micro',num_classes=num_classes, name=\"f1_score_micro\"), tf.keras.metrics.Precision(name=\"precision\"), tf.keras.metrics.Recall(name=\"recall\")])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Fit the model to the train data and validate it with the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We load the previously best weights to save time on training\n",
        "# if (exists(checkpoint_filepath)):\n",
        "    # softmax_model.load_weights(checkpoint_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvNQ1f9C3Ory",
        "outputId": "1b5f8cfa-4f8d-4532-c436-497bd26313d6"
      },
      "outputs": [],
      "source": [
        "softmax_history = softmax_model.fit(train_X, train_y_cat, validation_data=(test_X, test_y_cat), batch_size = 64, epochs=10, callbacks=[tensorboard_callback, early_stop_callback])\n",
        "# softmax_history = softmax_model.fit(train_X, train_y_cat, validation_data=(test_X, test_y_cat), batch_size = 64, epochs=10, callbacks=[model_checkpoint_callback, tensorboard_callback, early_stop_callback])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Plot important metrics"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### TensorBoard session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs/fit"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "3-YPKw9V3pfW",
        "outputId": "a509a96e-d168-4c1d-ccb9-185ddda13bf4"
      },
      "outputs": [],
      "source": [
        "plt.plot(softmax_history.history[\"loss\"], label=\"Train\")\n",
        "plt.plot(softmax_history.history[\"val_loss\"], label=\"Validation\")\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss evolution through epochs - Softmax')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "vYsmvi626L2g",
        "outputId": "227c99c2-6808-47e3-ad82-be7470ced0a1"
      },
      "outputs": [],
      "source": [
        "plt.plot(softmax_history.history[\"accuracy\"], label=\"Train\")\n",
        "plt.plot(softmax_history.history[\"val_accuracy\"], label=\"Validation\")\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy evolution through epochs - Softmax')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(softmax_history.history[\"precision\"], label=\"Train\")\n",
        "plt.plot(softmax_history.history[\"val_precision\"], label=\"Validation\")\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision evolution through epochs - Softmax')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(softmax_history.history[\"recall\"], label=\"Train\")\n",
        "plt.plot(softmax_history.history[\"val_recall\"], label=\"Validation\")\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Recall')\n",
        "plt.title('Recall evolution through epochs - Softmax')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### F1-Score"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### Macro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(softmax_history.history[\"f1_score\"], label=\"Train\")\n",
        "plt.plot(softmax_history.history[\"val_f1_score\"], label=\"Validation\")\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('F1 Score (Macro)')\n",
        "plt.title('F1 Score (Macro) evolution through epochs - Softmax')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### Micro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(softmax_history.history[\"f1_score_micro\"], label=\"Train\")\n",
        "plt.plot(softmax_history.history[\"val_f1_score_micro\"], label=\"Validation\")\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('F1 Score (Micro)')\n",
        "plt.title('F1 Score (Micro) evolution through epochs - Softmax')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ROC and AUC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot linewidth.\n",
        "lw = 2\n",
        "\n",
        "# Get score\n",
        "y_score = softmax_model.predict(test_X)\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(num_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(test_y_cat[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Compute micro-average ROC curve and ROC area\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(test_y_cat.ravel(), y_score.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "# Compute macro-average ROC curve and ROC area\n",
        "\n",
        "# First aggregate all false positive rates\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(num_classes)]))\n",
        "\n",
        "# Then interpolate all ROC curves at this points\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(num_classes):\n",
        "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "# Finally average it and compute AUC\n",
        "mean_tpr /= num_classes\n",
        "\n",
        "fpr[\"macro\"] = all_fpr\n",
        "tpr[\"macro\"] = mean_tpr\n",
        "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "# Plot all ROC curves\n",
        "plt.figure(1, figsize=(10,10))\n",
        "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "         label='micro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"micro\"]),\n",
        "         color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "         label='macro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"macro\"]),\n",
        "         color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "for i in range(num_classes):\n",
        "    plt.plot(fpr[i], tpr[i], lw=lw,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i, roc_auc[i]))\n",
        "\n",
        "#colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "#for i, color in zip(range(num_classes), colors):\n",
        "#    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
        "#             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "#             ''.format(i, roc_auc[i]))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Extension of Receiver Operating Characteristic to multi-class - Softmax')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Zoom in view of the upper left corner.\n",
        "plt.figure(2, figsize=(20,10))\n",
        "plt.xlim(0, 0.2)\n",
        "plt.ylim(0.8, 1)\n",
        "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "         label='micro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"micro\"]),\n",
        "         color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "         label='macro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"macro\"]),\n",
        "         color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "#colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "#for i, color in zip(range(num_classes), colors):\n",
        "#    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
        "#             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "#             ''.format(i, roc_auc[i]))\n",
        "    \n",
        "for i in range(num_classes):\n",
        "    plt.plot(fpr[i], tpr[i], lw=lw,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i, roc_auc[i]))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Zoomed - Extension of Receiver Operating Characteristic to multi-class - Softmax')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlp_model = Sequential()\n",
        "mlp_model.add(layers.Flatten(input_shape=(28,28)))\n",
        "mlp_model.add(layers.Dense(256, activation='relu'))\n",
        "mlp_model.add(layers.Dense(64, activation='relu'))\n",
        "mlp_model.add(layers.Dense(num_classes, activation=\"softmax\"))\n",
        "mlp_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlp_model.compile(loss = 'categorical_crossentropy', optimizer=SGD(learning_rate=0.0002, momentum=0.95),metrics=[\"accuracy\", tfa.metrics.F1Score(average='macro',num_classes=num_classes),tfa.metrics.F1Score(average='micro',num_classes=num_classes, name=\"f1_score_micro\"), tf.keras.metrics.Precision(name=\"precision\"), tf.keras.metrics.Recall(name=\"recall\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Callback to stop training if, after 2 epochs, the accuracy is not improving\n",
        "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Callback to save the weights of the best model\n",
        "checkpoint_filepath = '/tmp/checkpoint/mlp'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Logs and metrics from TensorBoard\n",
        "log_dir_fit = \"logs/fit/mlp/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir_fit, histogram_freq=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Fit the model to the train data and validate it with the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We load the previously best weights to save time on training\n",
        "# if (exists(checkpoint_filepath)):\n",
        "    # mlp_model.load_weights(checkpoint_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlp_history = mlp_model.fit(train_X, train_y_cat, validation_data=(test_X, test_y_cat), batch_size = 64, epochs=10, callbacks=[tensorboard_callback, early_stop_callback])\n",
        "# softmax_history = softmax_model.fit(train_X, train_y_cat, validation_data=(test_X, test_y_cat), batch_size = 64, epochs=10, callbacks=[model_checkpoint_callback, tensorboard_callback, early_stop_callback])\n",
        "# mlp_history = mlp_model.fit(train_X, train_y_cat, validation_data=(test_X, test_y_cat), batch_size = 64, epochs=10, callbacks=[model_checkpoint_callback, tensorboard_callback, early_stop_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Plot important metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### TensorBoard session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs/fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(mlp_history.history[\"loss\"], label=\"Train\")\n",
        "plt.plot(mlp_history.history[\"val_loss\"], label=\"Validation\")\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss evolution through epochs - MLP')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(mlp_history.history[\"accuracy\"], label=\"Train\")\n",
        "plt.plot(mlp_history.history[\"val_accuracy\"], label=\"Validation\")\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy evolution through epochs - MLP')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(mlp_history.history[\"precision\"], label=\"Train\")\n",
        "plt.plot(mlp_history.history[\"val_precision\"], label=\"Validation\")\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision evolution through epochs - MLP')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(mlp_history.history[\"recall\"], label=\"Train\")\n",
        "plt.plot(mlp_history.history[\"val_recall\"], label=\"Validation\")\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Recall')\n",
        "plt.title('Recall evolution through epochs - MLP')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### F1 Score"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### Macro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(mlp_history.history[\"f1_score\"], label=\"Train\")\n",
        "plt.plot(mlp_history.history[\"val_f1_score\"], label=\"Validation\")\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('F1 Score (Macro)')\n",
        "plt.title('F1 Score (Macro) evolution through epochs - MLP')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### Micro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(mlp_history.history[\"f1_score_micro\"], label=\"Train\")\n",
        "plt.plot(mlp_history.history[\"val_f1_score_micro\"], label=\"Validation\")\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('F1 Score (Micro)')\n",
        "plt.title('F1 Score (Micro) evolution through epochs - MLP')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ROC and AUC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot linewidth.\n",
        "lw = 2\n",
        "\n",
        "# Get score\n",
        "y_score = mlp_model.predict(test_X)\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(num_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(test_y_cat[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Compute micro-average ROC curve and ROC area\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(test_y_cat.ravel(), y_score.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "# Compute macro-average ROC curve and ROC area\n",
        "\n",
        "# First aggregate all false positive rates\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(num_classes)]))\n",
        "\n",
        "# Then interpolate all ROC curves at this points\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(num_classes):\n",
        "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "# Finally average it and compute AUC\n",
        "mean_tpr /= num_classes\n",
        "\n",
        "fpr[\"macro\"] = all_fpr\n",
        "tpr[\"macro\"] = mean_tpr\n",
        "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "# Plot all ROC curves\n",
        "plt.figure(1, figsize=(10,10))\n",
        "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "         label='micro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"micro\"]),\n",
        "         color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "         label='macro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"macro\"]),\n",
        "         color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "for i in range(num_classes):\n",
        "    plt.plot(fpr[i], tpr[i], lw=lw,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i, roc_auc[i]))\n",
        "\n",
        "#colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "#for i, color in zip(range(num_classes), colors):\n",
        "#    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
        "#             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "#             ''.format(i, roc_auc[i]))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Extension of Receiver Operating Characteristic to multi-class - MLP')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Zoom in view of the upper left corner.\n",
        "plt.figure(2, figsize=(20,10))\n",
        "plt.xlim(0, 0.2)\n",
        "plt.ylim(0.8, 1)\n",
        "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "         label='micro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"micro\"]),\n",
        "         color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "         label='macro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"macro\"]),\n",
        "         color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "#colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "#for i, color in zip(range(num_classes), colors):\n",
        "#    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
        "#             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "#             ''.format(i, roc_auc[i]))\n",
        "    \n",
        "for i in range(num_classes):\n",
        "    plt.plot(fpr[i], tpr[i], lw=lw,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i, roc_auc[i]))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Zoomed - Extension of Receiver Operating Characteristic to multi-class - MLP')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
